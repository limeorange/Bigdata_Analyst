{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "bbbb3e74-ac3e-44f1-b1fe-868ea4c710ca",
   "metadata": {
    "id": "yOX8hBk5gKrW"
   },
   "source": [
    "# ê¸°ì¶œ 3íšŒ_ì´ì§„ë¶„ë¥˜(í™•ë¥ ê°’)\n",
    "## ë³´í—˜ê°€ì… í™•ë¥  ì˜ˆì¸¡\n",
    "- ë¹…ë°ì´í„° ë¶„ì„ê¸°ì‚¬ 3íšŒ ì‹¤ê¸°\n",
    "- ì œê³µëœ ë°ì´í„°\n",
    "    - train.csv\n",
    "    - test.csv\n",
    "- ì˜ˆì¸¡í•  ì»¬ëŸ¼ : TravelInsurance\n",
    "\n",
    "## ì‹œí—˜ì—ì„œ ì œê³µëœ ì½”ë“œ\n",
    "~~~\n",
    "import pandas as pd\n",
    "a = pd.read_csv(\"train.csv\")\n",
    "b = pd.read_csv('test.csv')\n",
    "\n",
    "pd.DataFrame(ë³€ìˆ˜).to_csv('000000000.csv')\n",
    "~~~\n",
    "\n",
    "~~~\n",
    "# csv í˜•íƒœ\n",
    "# index,y_pred\n",
    "# 0,0.152467\n",
    "# 1,0.961511\n",
    "# 2,0.151313\n",
    "# 3,0.236632\n",
    "...\n",
    "# 494,0.121372\n",
    "# 495,0.965155\n",
    "# 496,0.986405\n",
    "\n",
    "~~~\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "25d94949-6881-4488-8073-18de9616e6b5",
   "metadata": {},
   "source": [
    "## ğŸ“Œ My Code\n",
    "- <span style='color: blue'>**TravelInsuranceê°€ 'ë¶„ë¥˜' ë¬¸ì œì´ë©´ì„œ 'í™•ë¥ ê°’'ì„ ë„ì¶œí•´ì•¼ í•¨**</span>\n",
    "- **roc_auc_score**: classifierê°€ 0, 1 ë²”ì£¼ì— ëŒ€í•´ ì˜ˆì¸¡í•œ í™•ë¥ ê°’ ì¤‘ ë²”ì£¼ 1ì— ëŒ€í•œ í™•ë¥ ê°’ ë„£ì–´ì¤˜ì•¼ í•¨.\n",
    "    - y_val_pred = model.predict_proba(X_val)[:, 1] / roc_auc_score(y_val, y_val_pred)\n",
    "- **accuracy_score**: classifierê°€ 0, 1ë¡œ ì˜ˆì¸¡í•œ ê°’ ë„£ì–´ì¤˜ì•¼ í•¨. model.predict(X_val)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 135,
   "id": "61cf48c6-be13-4165-8f54-faeef38933c4",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "(1192, 12) (298, 12) (1192,) (298,)\n",
      "(298,)\n",
      "0.7887109077040426\n",
      "     index    y_pred\n",
      "0        0  0.070000\n",
      "1        1  0.009306\n",
      "2        2  0.134476\n",
      "3        3  1.000000\n",
      "4        4  0.169833\n",
      "..     ...       ...\n",
      "492    492  0.020000\n",
      "493    493  0.975000\n",
      "494    494  0.300000\n",
      "495    495  1.000000\n",
      "496    496  0.990000\n",
      "\n",
      "[497 rows x 2 columns]\n"
     ]
    }
   ],
   "source": [
    "import pandas as pd\n",
    "train = pd.read_csv(\"https://raw.githubusercontent.com/lovedlim/inf/refs/heads/main/p4/3_2/train.csv\")\n",
    "test = pd.read_csv(\"https://raw.githubusercontent.com/lovedlim/inf/refs/heads/main/p4/3_2/test.csv\")\n",
    "\n",
    "# 1. ë°ì´í„° ìœ í˜• íŒŒì•…\n",
    "# ê²°ì¸¡ê°’ col: ì—†ìŒ / ë²”ì£¼í˜• col: Employment Type, GraduateOrNot, FrequentFlyer, EverTravelledAbroad\n",
    "# ì¢…ì†ë³€ìˆ˜: TravelInsurance\n",
    "# print(train.info())\n",
    "# print(test.info())\n",
    "# print(train.shape, test.shape)\n",
    "\n",
    "# 2. ë°ì´í„° ì „ì²˜ë¦¬\n",
    "# (1) X_full\n",
    "X = train.drop(['TravelInsurance'], axis=1)\n",
    "y = train['TravelInsurance']\n",
    "X_full = pd.concat([X, test], axis=0)\n",
    "X_full = X_full.drop(['Unnamed: 0'], axis=1)\n",
    "# print(X_full.shape, y.shape)\n",
    "\n",
    "# (2) ê²°ì¸¡ì¹˜ ì²˜ë¦¬\n",
    "# ê²°ì¸¡ì¹˜ ì—†ìŒ.\n",
    "\n",
    "# (3) ìˆ˜ì¹˜í˜• ë³€ìˆ˜ ìŠ¤ì¼€ì¼ë§ skip\n",
    "\n",
    "# (4) ë²”ì£¼í˜• ë³€ìˆ˜ ì¸ì½”ë”©\n",
    "X_full = pd.get_dummies(X_full)\n",
    "# print(X_full.shape)\n",
    "\n",
    "# 3. ë°ì´í„° ë¶„ë¦¬\n",
    "X_train = X_full[:train.shape[0]]\n",
    "X_test = X_full[train.shape[0]:]\n",
    "# print(X_train.shape, X_test.shape)\n",
    "\n",
    "from sklearn.model_selection import train_test_split\n",
    "X_train, X_val, y_train, y_val = train_test_split(X_train, y, test_size=0.2)\n",
    "print(X_train.shape, X_val.shape, y_train.shape, y_val.shape)\n",
    "\n",
    "# 4. ëª¨ë¸ í•™ìŠµ ë° ê²€ì¦\n",
    "from sklearn.ensemble import RandomForestClassifier\n",
    "model = RandomForestClassifier()\n",
    "model.fit(X_train, y_train)\n",
    "y_val_pred = model.predict_proba(X_val)[:, 1]\n",
    "print(y_val_pred.shape)\n",
    "\n",
    "# 5. ëª¨ë¸ í‰ê°€\n",
    "from sklearn.metrics import roc_auc_score\n",
    "roc_auc = roc_auc_score(y_val, y_val_pred)\n",
    "print(roc_auc)\n",
    "\n",
    "# 6. ê²°ê³¼ ì €ì¥\n",
    "y_pred = model.predict_proba(X_test)[:, 1]\n",
    "result = pd.DataFrame({'index': X_test.index, 'y_pred':y_pred})\n",
    "result.to_csv('result.csv', index=False)\n",
    "\n",
    "# 7. ê²°ê³¼ í™•ì¸\n",
    "check = pd.read_csv('result.csv')\n",
    "print(check)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 138,
   "id": "f3ad3f00-66c3-4141-8a17-bb95ca638776",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "np.float64(0.7591735966735966)"
      ]
     },
     "execution_count": 138,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "y_test = pd.read_csv(\"https://raw.githubusercontent.com/lovedlim/inf/refs/heads/main/p4/3_2/y_test.csv\")\n",
    "roc_auc_score(y_test, y_pred)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "d42678d1-c53c-476c-bdda-4fdd31641440",
   "metadata": {
    "id": "oC9z3kUJZ1HB"
   },
   "source": [
    "# ê¸°ì¶œ 4íšŒ_ë‹¤ì¤‘ë¶„ë¥˜\n",
    "## ì‹ ê·œ ê³ ê° ë¶„ë¥˜ ì˜ˆì¸¡\n",
    "- ìë™ì°¨ íšŒì‚¬ëŠ” ìƒˆë¡œìš´ ì „ëµì„ ìˆ˜ë¦½í•˜ê¸° ìœ„í•´ 4ê°œì˜ ì‹œì¥ìœ¼ë¡œ ì„¸ë¶„í™”í–ˆìŠµë‹ˆë‹¤.\n",
    "- ê¸°ì¡´ ê³ ê° ë¶„ë¥˜ ìë£Œë¥¼ ë°”íƒ•ìœ¼ë¡œ ì‹ ê·œ ê³ ê°ì´ ì–´ë–¤ ë¶„ë¥˜ì— ì†í• ì§€ ì˜ˆì¸¡í•´ì£¼ì„¸ìš”!\n",
    "\n",
    "\n",
    "- ì˜ˆì¸¡í•  ê°’(y): \"Segmentation\" (1,2,3,4)\n",
    "- í‰ê°€: Macro f1-score\n",
    "- data: train.csv, test.csv\n",
    "- ì œì¶œ í˜•ì‹:\n",
    "~~~\n",
    "ID,Segmentation\n",
    "458989,1\n",
    "458994,2\n",
    "459000,3\n",
    "459003,4\n",
    "~~~\n",
    "\n",
    "## ë‹µì•ˆ ì œì¶œ ì°¸ê³ \n",
    "- ì•„ë˜ ì½”ë“œ ì˜ˆì¸¡ë³€ìˆ˜ì™€ ìˆ˜í—˜ë²ˆí˜¸ë¥¼ ê°œì¸ë³„ë¡œ ë³€ê²½í•˜ì—¬ í™œìš©\n",
    "- pd.DataFrame({'ID': test.ID, 'Segmentation': pred}).to_csv('003000000.csv', index=False)\n",
    "\n",
    "## ë…¸íŠ¸ë¶ êµ¬ë¶„\n",
    "- basic: ìˆ˜ì¹˜í˜• ë°ì´í„°ë§Œ í™œìš© -> í•™ìŠµ ë° testë°ì´í„° ì˜ˆì¸¡\n",
    "- intermediate: ë²”ì£¼í˜• ë°ì´í„°ë„ í™œìš© -> í•™ìŠµ ë° testë°ì´í„° ì˜ˆì¸¡\n",
    "- advanced: í•™ìŠµ ë° êµì°¨ ê²€ì¦(ëª¨ë¸ í‰ê°€) -> í•˜ì´í¼íŒŒë¼ë¯¸í„° íŠœë‹ -> testë°ì´í„° ì˜ˆì¸¡"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "bbf20892-204a-4ecf-9552-8eafa3ce1bcf",
   "metadata": {},
   "source": [
    "## ğŸ“Œ My Code"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 30,
   "id": "c0883bcd-6070-408e-875a-bf36d1e4b69d",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "(6665, 28) (2154, 28)\n",
      "(5332, 28) (1333, 28) (5332,) (1333,)\n",
      "0.4940375859305005\n",
      "          ID  Segmentation\n",
      "0     458989             2\n",
      "1     458994             3\n",
      "2     459000             3\n",
      "3     459003             3\n",
      "4     459005             1\n",
      "...      ...           ...\n",
      "2149  467950             1\n",
      "2150  467954             4\n",
      "2151  467958             1\n",
      "2152  467961             3\n",
      "2153  467968             4\n",
      "\n",
      "[2154 rows x 2 columns]\n"
     ]
    }
   ],
   "source": [
    "import pandas as pd\n",
    "\n",
    "# ë°ì´í„° ë¶ˆëŸ¬ì˜¤ê¸°\n",
    "train = pd.read_csv(\"https://raw.githubusercontent.com/lovedlim/inf/refs/heads/main/p4/4_2/train.csv\")\n",
    "test = pd.read_csv(\"https://raw.githubusercontent.com/lovedlim/inf/refs/heads/main/p4/4_2/test.csv\")\n",
    "\n",
    "# 1. ë°ì´í„° ìœ í˜• íŒŒì•…\n",
    "# ê²°ì¸¡ê°’: ì—†ìŒ, \n",
    "# ë²”ì£¼í˜•: ['Gender', 'Ever_Married', 'Graduated', 'Profession', 'Spending_Score', 'Var_1']\n",
    "# target: 'Segmentation'\n",
    "# print(train.info())\n",
    "# print(test.info())\n",
    "# print(train.select_dtypes('object').columns)\n",
    "# print(train.shape, test.shape)\n",
    "\n",
    "# 2. ë°ì´í„° ì „ì²˜ë¦¬\n",
    "# X_full\n",
    "X = train.drop(['Segmentation'], axis=1)\n",
    "y = train['Segmentation']\n",
    "X_full = pd.concat([X, test], axis=0)\n",
    "X_full = X_full.drop(['ID'], axis=1)\n",
    "# print(X_full.shape)\n",
    "\n",
    "\n",
    "# ê²°ì¸¡ì¹˜ ì²˜ë¦¬ => ì—†ìŒ.\n",
    "# print(X_full.isna().sum())\n",
    "\n",
    "# ìˆ˜ì¹˜í˜• ë³€ìˆ˜ => ìƒëµ.\n",
    "\n",
    "\n",
    "# ë²”ì£¼í˜• ë³€ìˆ˜\n",
    "X_full = pd.get_dummies(X_full)\n",
    "# print(X_full.shape)\n",
    "\n",
    "# 3. ë°ì´í„° ë¶„ë¦¬\n",
    "X_train = X_full[:train.shape[0]]\n",
    "X_test = X_full[train.shape[0]:]\n",
    "print(X_train.shape, X_test.shape)\n",
    "\n",
    "from sklearn.model_selection import train_test_split\n",
    "X_train, X_val, y_train, y_val = train_test_split(X_train, y, test_size=0.2)\n",
    "\n",
    "print(X_train.shape, X_val.shape, y_train.shape, y_val.shape)\n",
    "\n",
    "# 4. ëª¨ë¸ í•™ìŠµ ë° ê²€ì¦\n",
    "from sklearn.ensemble import RandomForestClassifier\n",
    "model = RandomForestClassifier()\n",
    "model.fit(X_train, y_train)\n",
    "y_val_pred = model.predict(X_val)\n",
    "# print(y_val_pred.shape)\n",
    "\n",
    "# 5. ëª¨ë¸ í‰ê°€\n",
    "from sklearn.metrics import f1_score\n",
    "f1_macro_score = f1_score(y_val, y_val_pred, average='macro')\n",
    "print(f1_macro_score)\n",
    "# help(sklearn.metrics.f1_score)\n",
    "\n",
    "# 6. ê²°ê³¼ ì €ì¥\n",
    "y_pred = model.predict(X_test)\n",
    "result = pd.DataFrame({'ID': test['ID'], 'Segmentation': y_pred})\n",
    "result.to_csv('result4_2.csv', index=False)\n",
    "\n",
    "check = pd.read_csv('result4_2.csv')\n",
    "print(check)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "22d65391-0828-41f6-b5a1-87cd0a2438de",
   "metadata": {
    "id": "-uyZnljmfPU0"
   },
   "source": [
    "# ê¸°ì¶œ 5íšŒ_íšŒê·€\n",
    "\n",
    "## ì¤‘ê³  ìë™ì°¨ ê°€ê²© ì˜ˆì¸¡\n",
    "- ìë™ì°¨ ê°€ê²©ì„ ì˜ˆì¸¡í•´ì£¼ì„¸ìš”!\n",
    "\n",
    "\n",
    "- ì˜ˆì¸¡í•  ê°’(y): price\n",
    "- í‰ê°€: RMSE (Root Mean Squared Error)\n",
    "- data: train.csv, test.csv\n",
    "- ì œì¶œ í˜•ì‹: result.csvíŒŒì¼ì„ ì•„ë˜ì™€ ê°™ì€ í˜•ì‹(ìˆ˜ì¹˜í˜•)ìœ¼ë¡œ ì œì¶œ\n",
    "~~~\n",
    "pred\n",
    "11000\n",
    "20500\n",
    "19610\n",
    "...\n",
    "11995\n",
    "~~~\n",
    "\n",
    "## ë‹µì•ˆ ì œì¶œ ì°¸ê³ \n",
    "- pd.read_csv('result.csv') ë¡œ ì œì¶œ ì½”ë“œ í™•ì¸"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "4fd09db2-671a-411c-83d4-302a4782bce7",
   "metadata": {},
   "source": [
    "## ğŸ“Œ My Code"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 22,
   "id": "11bab347-376a-4eda-8d1e-6e6d9707ba53",
   "metadata": {
    "id": "30wq46-FfSt_"
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "1359.5954531900989\n"
     ]
    }
   ],
   "source": [
    "import pandas as pd\n",
    "\n",
    "train = pd.read_csv(\"https://raw.githubusercontent.com/lovedlim/inf/refs/heads/main/p4/5_2/train.csv\")\n",
    "test = pd.read_csv(\"https://raw.githubusercontent.com/lovedlim/inf/refs/heads/main/p4/5_2/test.csv\")\n",
    "\n",
    "# 1. ë°ì´í„° ìœ í˜• íŒŒì•…\n",
    "# ê²°ì¸¡ê°’ col: ì—†ìŒ\n",
    "# ë²”ì£¼í˜• col: ['model', 'transmission', 'fuelType']\n",
    "# target: 'price' \n",
    "# print(train.info())\n",
    "# print(test.info())\n",
    "# print(train.select_dtypes('object').columns)\n",
    "\n",
    "# 2. ë°ì´í„° ì „ì²˜ë¦¬\n",
    "# (1) X_full: (5576, 8)\n",
    "X = train.drop(['price'], axis=1)\n",
    "y = train['price']\n",
    "X_full = pd.concat([X, test], axis=0)\n",
    "# print(X.shape, test.shape, y.shape, X_full.shape)\n",
    "\n",
    "# (2) ê²°ì¸¡ì¹˜ ì²˜ë¦¬: fillna() => ê²°ì¸¡ì¹˜ê°€ ì—†ìŒ. Pass\n",
    "\n",
    "# (3) ìˆ˜ì¹˜í˜• ë³€ìˆ˜ ìŠ¤ì¼€ì¼ë§ => Pass\n",
    "\n",
    "# (4) ë²”ì£¼í˜• ë³€ìˆ˜ ìŠ¤ì¼€ì¼ë§\n",
    "X_full = pd.get_dummies(X_full)\n",
    "# print(X_full)\n",
    "# print(X_full.shape) # (5376, 30)\n",
    "\n",
    "# 3. ë°ì´í„° ë¶„ë¦¬\n",
    "X_train = X_full[:train.shape[0]]\n",
    "X_test = X_full[train.shape[0]:]\n",
    "# print(X_train.shape, X_test.shape) # (3759, 30) (1617, 30)\n",
    "\n",
    "from sklearn.model_selection import train_test_split\n",
    "X_train, X_val, y_train, y_val = train_test_split(X_train, y, test_size=0.2)\n",
    "# print(X_train.shape, X_val.shape, y_train.shape, y_val.shape) # (3007, 30) (752, 30) (3007,) (752,)\n",
    "\n",
    "# 4. ëª¨ë¸í•™ìŠµ ë° ê²€ì¦\n",
    "from sklearn.ensemble import RandomForestRegressor\n",
    "model = RandomForestRegressor()\n",
    "model.fit(X_train, y_train)\n",
    "y_val_pred = model.predict(X_val)\n",
    "# print(y_val_pred.shape) # (752,)\n",
    "\n",
    "# 5. ëª¨ë¸ í‰ê°€\n",
    "from sklearn.metrics import root_mean_squared_error\n",
    "rmse = root_mean_squared_error(y_val, y_val_pred)\n",
    "print(rmse)\n",
    "\n",
    "# 6. ê²°ê³¼ ì €ì¥\n",
    "y_pred = model.predict(X_test)\n",
    "# print(y_pred.shape)\n",
    "# print(y_pred)\n",
    "\n",
    "result = pd.DataFrame({'pred':y_pred})\n",
    "result.to_csv('result_52.csv', index=False)\n",
    "\n",
    "check = pd.read_csv('result_52.csv')\n",
    "# print(check)\n",
    "# print(check.shape)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 23,
   "id": "77f0c295-9075-402e-ac8f-fada118ed309",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "1451.8524103823402\n"
     ]
    }
   ],
   "source": [
    "# ì‹¤ì œ í‰ê°€ ê²°ê³¼ í™•ì¸\n",
    "\n",
    "y = pd.read_csv(\"https://raw.githubusercontent.com/lovedlim/inf/refs/heads/main/p4/5_2/y.csv\")\n",
    "print(root_mean_squared_error(y, y_pred))"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "095e6cea-41af-4263-8263-008bb76aedf8",
   "metadata": {
    "id": "JiFc-11Gk38n"
   },
   "source": [
    "# ê¸°ì¶œ 6íšŒ_ë‹¤ì¤‘ë¶„ë¥˜\n",
    "## ë‚œë°© ë¶€í•˜ ë‹¨ê³„ ì˜ˆì¸¡\n",
    "\n",
    "- ì˜ˆì¸¡í•  ê°’(y): Heat_Load (Very Low, Low, Medium, High, Very High)\n",
    "- í‰ê°€: f1-macro\n",
    "- data: train.csv, test.csv\n",
    "- ì œì¶œ í˜•ì‹: result.csvíŒŒì¼ì„ ì•„ë˜ì™€ ê°™ì€ í˜•ì‹ìœ¼ë¡œ ì œì¶œ\n",
    "~~~\n",
    "pred\n",
    "Very Low\n",
    "Low\n",
    "High\n",
    "...\n",
    "Very High\n",
    "~~~\n",
    "\n",
    "## ë‹µì•ˆ ì œì¶œ ì°¸ê³ \n",
    "- pd.read_csv('result.csv') ë¡œ ì œì¶œ ì½”ë“œ í™•ì¸"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "f2f04270-706a-4c7b-8a36-99c83e6c6846",
   "metadata": {},
   "source": [
    "## ğŸ“Œ My Code"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 23,
   "id": "8bfd7043-928a-48bc-ac92-ac783cff0446",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "rfc_score 0.9019376857444156\n",
      "hgbc_score 0.8797812408940308\n",
      "          pred\n",
      "0          Low\n",
      "1         High\n",
      "2         High\n",
      "3          Low\n",
      "4          Low\n",
      "..         ...\n",
      "226   Very Low\n",
      "227     Medium\n",
      "228   Very Low\n",
      "229        Low\n",
      "230  Very High\n",
      "\n",
      "[231 rows x 1 columns]\n"
     ]
    }
   ],
   "source": [
    "import pandas as pd\n",
    "train = pd.read_csv(\"https://raw.githubusercontent.com/lovedlim/inf/refs/heads/main/p4/6_2/energy_train.csv\")\n",
    "test = pd.read_csv(\"https://raw.githubusercontent.com/lovedlim/inf/refs/heads/main/p4/6_2/energy_test.csv\")\n",
    "\n",
    "# 1. ë°ì´í„° ìœ í˜• íŒŒì•…\n",
    "# ê²°ì¸¡ê°’: X\n",
    "# ë²”ì£¼í˜•: ['Roof', 'Height', 'Orient']\n",
    "# target: Heat_Load\n",
    "\n",
    "# print(train.info())\n",
    "# print(test.info())\n",
    "# print(train.shape, test.shape) # (537, 10) (231, 9)\n",
    "# print(train.select_dtypes('object').columns)\n",
    "\n",
    "# 2. ë°ì´í„° ì „ì²˜ë¦¬\n",
    "# (1) X_full\n",
    "X = train.drop(['Heat_Load'], axis=1)\n",
    "y = train['Heat_Load']\n",
    "X_full = pd.concat([X, test], axis=0)\n",
    "# print(X.shape, test.shape, y.shape) # (537, 9) (231, 9) (537,)\n",
    "\n",
    "# (2) ê²°ì¸¡ê°’ ì²˜ë¦¬ => X\n",
    "\n",
    "# (3) ìˆ˜ì¹˜í˜• ë³€ìˆ˜ ìŠ¤ì¼€ì¼ë§ => X\n",
    "\n",
    "# (4) ë²”ì£¼í˜• ë³€ìˆ˜ ì¸ì½”ë”©\n",
    "X_full = pd.get_dummies(X_full)\n",
    "# print(X_full)\n",
    "# print(X_full.shape) # (768, 16)\n",
    "\n",
    "# 3. ë°ì´í„° ë¶„ë¦¬\n",
    "X_train = X_full[:train.shape[0]]\n",
    "X_test = X_full[train.shape[0]:]\n",
    "\n",
    "from sklearn.model_selection import train_test_split\n",
    "X_train, X_val, y_train, y_val = train_test_split(X_train, y, test_size=0.2)\n",
    "# print(X_train.shape, X_val.shape, y_train.shape, y_val.shape) # (429, 16) (108, 16) (429,) (108,)\n",
    "\n",
    "# 4. ëª¨ë¸ í•™ìŠµ ë° ê²€ì¦\n",
    "from sklearn.ensemble import RandomForestClassifier\n",
    "rfc = RandomForestClassifier()\n",
    "rfc.fit(X_train, y_train)\n",
    "y_val_pred_rfc = rfc.predict(X_val)\n",
    "# print(y_val_pred_rfc)\n",
    "# print(y_val_pred_rfc.shape) # (108,)\n",
    "\n",
    "from sklearn.ensemble import HistGradientBoostingClassifier\n",
    "hgbc = HistGradientBoostingClassifier()\n",
    "hgbc.fit(X_train, y_train)\n",
    "y_val_pred_hgbc = hgbc.predict(X_val)\n",
    "# print(y_val_pred_hgbc)\n",
    "# print(y_val_pred_hgbc.shape) # (108,)\n",
    "\n",
    "# 5. ëª¨ë¸ í‰ê°€\n",
    "from sklearn.metrics import f1_score\n",
    "rfc_score = f1_score(y_val, y_val_pred_rfc, average='macro')\n",
    "hgbc_score = f1_score(y_val, y_val_pred_hgbc, average='macro')\n",
    "print('rfc_score', rfc_score)\n",
    "print('hgbc_score', hgbc_score)\n",
    "\n",
    "# 6. ê²°ê³¼ ì €ì¥\n",
    "y_pred = rfc.predict(X_test)\n",
    "# print(y_pred)\n",
    "# print(y_pred.shape) # (231,)\n",
    "\n",
    "result = pd.DataFrame({'pred':y_pred})\n",
    "result.to_csv('result_62.csv', index=False)\n",
    "\n",
    "check = pd.read_csv('result_62.csv')\n",
    "print(check)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "948f7581-1c3f-48a3-b6e9-29539dee8a8e",
   "metadata": {
    "id": "KBEr9K-lV_M6"
   },
   "source": [
    "# ê¸°ì¶œ 7íšŒ_íšŒê·€\n",
    "## mart íŒë§¤ ë°ì´í„°ë¥¼ ê¸°ë°˜ìœ¼ë¡œ íŒë§¤ì•¡ ì˜ˆì¸¡\n",
    "- ì œê³µëœ ë°ì´í„° ëª©ë¡: mart_train.csv (í›ˆë ¨ ë°ì´í„°), mart_test.csv (í‰ê°€ìš© ë°ì´í„°)\n",
    "- ì˜ˆì¸¡í•  ì»¬ëŸ¼: total (ì´ íŒë§¤ì•¡)\n",
    "í•™ìŠµìš© ë°ì´í„°(mart_train.csv)ë¥¼ ì´ìš©í•˜ì—¬ ì´ íŒë§¤ì•¡ì„ ì˜ˆì¸¡í•˜ëŠ” ëª¨ë¸ì„ ë§Œë“  í›„, ì´ë¥¼ í‰ê°€ìš© ë°ì´í„°(mart_test.csv)ì— ì ìš©í•˜ì—¬ ì–»ì€ ì˜ˆì¸¡ê°’ì„ ë‹¤ìŒê³¼ ê°™ì€ í˜•ì‹ì˜ CSV íŒŒì¼ë¡œ ìƒì„±í•˜ì‹œì˜¤.\n",
    "- ì œì¶œ íŒŒì¼ì€ ë‹¤ìŒ í•œ ê°œì˜ ì»¬ëŸ¼ì„ í¬í•¨í•´ì•¼ í•©ë‹ˆë‹¤.\n",
    "- pred: ì˜ˆì¸¡ëœ ì´ íŒë§¤ì•¡\n",
    "- ì œì¶œ íŒŒì¼ëª…: 'result.csv' ì œì¶œí•œ ëª¨ë¸ì˜ ì„±ëŠ¥ì€ RMSE(Root Mean Square Error) í‰ê°€ì§€í‘œì— ë”°ë¼ ì±„ì í•œë‹¤.\n",
    "- ì œì¶œ CSV íŒŒì¼ëª… ë° í˜•íƒœ: result.csv\n",
    "\n",
    "~~~\n",
    "pred\n",
    "10000\n",
    "20000\n",
    "30000\n",
    "40000\n",
    "...\n",
    "~~~\n",
    "\n",
    "## ë‹µì•ˆ ì œì¶œ ì°¸ê³ \n",
    "- pd.read_csv('result.csv') ë¡œ ì œì¶œ ì½”ë“œ í™•ì¸"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "21a7bc87-5f96-419c-8007-b3166f1c6e88",
   "metadata": {},
   "source": [
    "## ğŸ“Œ My Code"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "id": "b27c3699-2b87-4888-a84e-cebd61e8bb96",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "score_rf 379654.48854407197\n",
      "score_hgb 409161.0203967835\n",
      "            pred\n",
      "0    356511.0150\n",
      "1    674935.3800\n",
      "2    263410.7175\n",
      "3    593099.0100\n",
      "4    438679.7100\n",
      "..           ...\n",
      "295  519270.0975\n",
      "296  435027.1275\n",
      "297  475343.0325\n",
      "298  396731.0025\n",
      "299  494153.1000\n",
      "\n",
      "[300 rows x 1 columns]\n"
     ]
    }
   ],
   "source": [
    "import pandas as pd\n",
    "train = pd.read_csv(\"https://raw.githubusercontent.com/lovedlim/inf/refs/heads/main/p4/7_2/mart_train.csv\")\n",
    "test = pd.read_csv(\"https://raw.githubusercontent.com/lovedlim/inf/refs/heads/main/p4/7_2/mart_test.csv\")\n",
    "\n",
    "# 1. ë°ì´í„° ìœ í˜• íŒŒì•…\n",
    "# ê²°ì¸¡ì¹˜: X\n",
    "# ë²”ì£¼í˜•: ['branch', 'city', 'customer_type', 'gender', 'product_line', 'payment_method', 'time_of_day', 'day_name']\n",
    "# target: total\n",
    "# print(train.info())\n",
    "# print(test.info())\n",
    "# print(train)\n",
    "# print(train.shape, test.shape) # (700, 10) (300, 9)\n",
    "# print(train.select_dtypes('object').columns)\n",
    "\n",
    "# 2. ë°ì´í„° ì „ì²˜ë¦¬ (4)\n",
    "# (1) X_full\n",
    "X = train.drop(['total'], axis=1)\n",
    "y = train['total']\n",
    "X_full = pd.concat([X, test], axis=0)\n",
    "\n",
    "# (2) ê²°ì¸¡ì¹˜: X\n",
    "\n",
    "# (3) ìˆ˜ì¹˜í˜• ë³€ìˆ˜ ìŠ¤ì¼€ì¼ë§: X\n",
    "\n",
    "# (4) ë²”ì£¼í˜• ë³€ìˆ˜ ì¸ì½”ë”©\n",
    "X_full = pd.get_dummies(X_full)\n",
    "# print(X_full)\n",
    "# print(X_full.shape) # (1000, 30)\n",
    "\n",
    "# 3. ë°ì´í„° ë¶„ë¦¬ (X_train, X_test / train_test_split)\n",
    "X_train = X_full[:train.shape[0]]\n",
    "X_test = X_full[train.shape[0]:]\n",
    "# print(X_train.shape, X_test.shape) # (700, 30) (300, 30)\n",
    "\n",
    "from sklearn.model_selection import train_test_split\n",
    "X_train, X_val, y_train, y_val = train_test_split(X_train, y, test_size=0.2)\n",
    "# print(X_train.shape, X_val.shape, y_train.shape, y_val.shape) # (560, 30) (140, 30) (560,) (140,)\n",
    "\n",
    "# 4. ëª¨ë¸ í•™ìŠµ\n",
    "from sklearn.ensemble import RandomForestRegressor\n",
    "RF = RandomForestRegressor()\n",
    "RF.fit(X_train, y_train)\n",
    "y_val_pred_rf = RF.predict(X_val)\n",
    "# print(y_val_pred_rf)\n",
    "# print(y_val_pred_rf.shape) # (140,)\n",
    "\n",
    "from sklearn.ensemble import HistGradientBoostingRegressor\n",
    "HGB = HistGradientBoostingRegressor()\n",
    "HGB.fit(X_train, y_train)\n",
    "y_val_pred_hgb = HGB.predict(X_val)\n",
    "# print(y_val_pred_hgb)\n",
    "# print(y_val_pred_hgb.shape) # (140,)\n",
    "\n",
    "# 5. ëª¨ë¸ í‰ê°€\n",
    "from sklearn.metrics import root_mean_squared_error\n",
    "score_rf = root_mean_squared_error(y_val, y_val_pred_rf)\n",
    "print('score_rf', score_rf)\n",
    "\n",
    "score_hgb = root_mean_squared_error(y_val, y_val_pred_hgb)\n",
    "print('score_hgb', score_hgb)\n",
    "\n",
    "# 6. ê²°ê³¼ ì €ì¥\n",
    "y_pred = RF.predict(X_test)\n",
    "# print(y_pred)\n",
    "# print(y_pred.shape) # (300,)\n",
    "\n",
    "result = pd.DataFrame({'pred': y_pred})\n",
    "result.to_csv('result_72.csv', index=False)\n",
    "\n",
    "check = pd.read_csv('result_72.csv')\n",
    "print(check)\n",
    "# print(check.shape) # (300, 1)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "05aff1f2-7720-4c88-9a22-944f978cc509",
   "metadata": {
    "id": "VmFg5UN40fYV"
   },
   "source": [
    "# ê¸°ì¶œ 8íšŒ_íšŒê·€\n",
    "## í†µì‹ ì‚¬ì—ì„œ ê³ ê°ì—ê²Œ ì²­êµ¬ë  ì´ ê¸ˆì•¡ ì˜ˆì¸¡\n",
    "- ì œê³µëœ ë°ì´í„° ëª©ë¡:\n",
    "    - churn_train.csv(í›ˆë ¨ ë°ì´í„°)\n",
    "    - churn_test.csv(í‰ê°€ìš© ë°ì´í„°)\n",
    "- ì˜ˆì¸¡í•  ì»¬ëŸ¼: TotalCharges(ì´ ì²­êµ¬ì•¡)\n",
    "- í•™ìŠµìš© ë°ì´í„°(churn_train.csv)ë¥¼ ì´ìš©í•˜ì—¬ ì´ ì²­êµ¬ì•¡ì„ ì˜ˆì¸¡í•˜ëŠ” ëª¨ë¸ì„ ë§Œë“  í›„ ì´ë¥¼ í‰ê°€ìš© ë°ì´í„°(churn_test.csv)\n",
    "ì— ì ìš©í•´ ì–»ì€ ì˜ˆì¸¡ê°’ì„ ë‹¤ìŒê³¼ ê°™ì€ í˜•ì‹ì˜ CSV íŒŒì¼ë¡œ ìƒì„±í•˜ì‹œì˜¤.\n",
    "\n",
    "- ì œì¶œ íŒŒì¼ì€ ë‹¤ìŒ 1ê°œì˜ ì»¬ëŸ¼ì„ í¬í•¨í•´ì•¼ í•œë‹¤.\n",
    "    - pred: ì˜ˆì¸¡ëœ ì´ ì²­êµ¬ì•¡\n",
    "    - ì œì¶œ íŒŒì¼ëª…: â€˜result.csvâ€™\n",
    "- ì œì¶œí•œ ëª¨ë¸ì˜ ì„±ëŠ¥ì€ MAE(Mean Absolute Error) í‰ê°€ì§€í‘œì— ë”°ë¼ ì±„ì í•œë‹¤."
   ]
  },
  {
   "cell_type": "markdown",
   "id": "601b85eb-aa86-4c7f-b95d-6b20a3ae702f",
   "metadata": {},
   "source": [
    "## ğŸ“Œ My Code"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "id": "1255eb7c-eb24-4537-8e66-b9be616f2441",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "score_RF 919.4194192576861\n",
      "score_HGB 921.2422028508327\n",
      "(1764,)\n",
      "           pred\n",
      "0     3518.5767\n",
      "1      914.8106\n",
      "2     4238.5076\n",
      "3      887.3167\n",
      "4     1500.7673\n",
      "...         ...\n",
      "1759   312.7409\n",
      "1760  4009.8700\n",
      "1761  4100.2494\n",
      "1762   867.8224\n",
      "1763  3676.1736\n",
      "\n",
      "[1764 rows x 1 columns]\n",
      "(1764, 1)\n"
     ]
    }
   ],
   "source": [
    "import pandas as pd\n",
    "train = pd.read_csv(\"https://raw.githubusercontent.com/lovedlim/inf/refs/heads/main/p4/8_2/churn_train.csv\")\n",
    "test = pd.read_csv(\"https://raw.githubusercontent.com/lovedlim/inf/refs/heads/main/p4/8_2/churn_test.csv\")\n",
    "\n",
    "# 1. ë°ì´í„° ìœ í˜• íŒŒì•…\n",
    "# ê²°ì¸¡ê°’: X\n",
    "# ë²”ì£¼í˜•: ['customerID', 'gender', 'Partner', 'Dependents', 'PhoneService',\n",
    "       # 'MultipleLines', 'InternetService', 'OnlineSecurity', 'OnlineBackup',\n",
    "       # 'DeviceProtection', 'TechSupport', 'StreamingTV', 'StreamingMovies',\n",
    "       # 'Contract', 'PaperlessBilling', 'PaymentMethod']\n",
    "# target: TotalCharges\n",
    "# ì œì™¸í• col: customerID\n",
    "\n",
    "# print(train)\n",
    "# print(test)\n",
    "# print(train.info())\n",
    "# print(test.info())\n",
    "# print(train.select_dtypes('object').columns)\n",
    "# print(train.shape, test.shape) # (4116, 19) (1764, 18)\n",
    "\n",
    "# 2. ë°ì´í„° ì „ì²˜ë¦¬\n",
    "# (1) X_full\n",
    "X = train.drop(['TotalCharges'], axis=1)\n",
    "y = train['TotalCharges']\n",
    "# print(X.shape, y.shape) # (4116, 18) (4116,)\n",
    "\n",
    "X_full = pd.concat([X, test], axis=0)\n",
    "X_full = X_full.drop(['customerID'], axis=1)\n",
    "# print(X_full.shape, X.shape, test.shape) # (5880, 17) (4116, 18) (1764, 18)\n",
    "\n",
    "# (2) ê²°ì¸¡ì¹˜ ì²˜ë¦¬ => X\n",
    "\n",
    "# (3) ìˆ˜ì¹˜í˜• ë³€ìˆ˜ ìŠ¤ì¼€ì¼ë§ => X\n",
    "\n",
    "# (4) ë²”ì£¼í˜• ë³€ìˆ˜ ì¸ì½”ë”©\n",
    "X_full = pd.get_dummies(X_full)\n",
    "# print(X_full.shape) # (5880, 43)\n",
    "# print(X_full)\n",
    "\n",
    "# 3. ë°ì´í„° ë¶„ë¦¬ - X_train, X_test / train_test_split\n",
    "X_train = X_full[:train.shape[0]]\n",
    "X_test = X_full[train.shape[0]:]\n",
    "# print(X_train.shape, X_test.shape) # (4116, 43) (1764, 43)\n",
    "\n",
    "from sklearn.model_selection import train_test_split\n",
    "X_train, X_val, y_train, y_val = train_test_split(X_train, y, test_size=0.2)\n",
    "# print(X_train.shape, X_val.shape, y_train.shape, y_val.shape) # (3292, 43) (824, 43) (3292,) (824,)\n",
    "\n",
    "# 4. ëª¨ë¸ í•™ìŠµ - RandomForestRegressor, HistGradientBoostingRegressor\n",
    "from sklearn.ensemble import RandomForestRegressor\n",
    "RF = RandomForestRegressor()\n",
    "RF.fit(X_train, y_train)\n",
    "y_val_pred_rf = RF.predict(X_val)\n",
    "# print(y_val_pred_rf)\n",
    "# print(y_val_pred_rf.shape) # (824,)\n",
    "\n",
    "from sklearn.ensemble import HistGradientBoostingRegressor\n",
    "HGB = HistGradientBoostingRegressor()\n",
    "HGB.fit(X_train, y_train)\n",
    "y_val_pred_hgb = HGB.predict(X_val)\n",
    "# print(y_val_pred_hgb)\n",
    "# print(y_val_pred_hgb.shape) # (824,)\n",
    "\n",
    "# 5. ëª¨ë¸ í‰ê°€ - mean_absolute_error(?)\n",
    "from sklearn.metrics import mean_absolute_error\n",
    "score_RF = mean_absolute_error(y_val, y_val_pred_rf)\n",
    "print('score_RF', score_RF)\n",
    "\n",
    "score_HGB = mean_absolute_error(y_val, y_val_pred_hgb)\n",
    "print('score_HGB', score_HGB)\n",
    "\n",
    "# 6. ê²°ê³¼ ì €ì¥\n",
    "y_pred = RF.predict(X_test)\n",
    "print(y_pred.shape) # (1764,)\n",
    "# print(y_pred)\n",
    "\n",
    "result = pd.DataFrame({'pred':y_pred})\n",
    "result.to_csv('result_82.csv', index=False)\n",
    "\n",
    "check = pd.read_csv('result_82.csv')\n",
    "print(check)\n",
    "print(check.shape)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "47004b08-daf1-47fe-8f72-c74ec0239004",
   "metadata": {
    "id": "ben18EnnhH5K"
   },
   "source": [
    "# ê¸°ì¶œ 9íšŒ_ë‹¤ì¤‘ë¶„ë¥˜\n",
    "## ë†ì‘ë¬¼ì—ì„œ ë†ì•½ ê²€ì¶œ ì—¬ë¶€ ì˜ˆì¸¡\n",
    "-\tì œê³µëœ ë°ì´í„° ëª©ë¡:\n",
    "    - farm_train.csv (í›ˆë ¨ ë°ì´í„°)\n",
    "    - farm_test.csv (í‰ê°€ìš© ë°ì´í„°)\n",
    "-\tì˜ˆì¸¡í•  ì»¬ëŸ¼: ë†ì•½ê²€ì¶œì—¬ë¶€ (0:ë¯¸ê²€ì¶œ, 1:ê²€ì¶œ, 2:ì¬ê²€ì‚¬ í•„ìš”)\n",
    "\n",
    "í•™ìŠµìš© ë°ì´í„°(farm_train.csv)ë¥¼ ì´ìš©í•˜ì—¬ ë†ì•½ ê²€ì¶œ ì—¬ë¶€ë¥¼ ì˜ˆì¸¡í•˜ëŠ” ëª¨ë¸ì„ êµ¬ì¶•í•œ í›„, ì´ë¥¼ í‰ê°€ìš© ë°ì´í„°(farm_test.csv)ì— ì ìš©í•˜ì—¬ ì˜ˆì¸¡ ê²°ê³¼ë¥¼ ë‹¤ìŒê³¼ ê°™ì€ í˜•ì‹ì˜ CSV íŒŒì¼ë¡œ ìƒì„±í•˜ì‹œì˜¤.\n",
    "\n",
    "ì œì¶œ íŒŒì¼ì€ ë‹¤ìŒ í•œ ê°œì˜ ì»¬ëŸ¼ì„ í¬í•¨í•´ì•¼ í•©ë‹ˆë‹¤.\n",
    "- pred: ì˜ˆì¸¡ëœ ê²€ì¶œ ì—¬ë¶€\n",
    "- ì œì¶œ íŒŒì¼ëª…: 'result.csv'\n",
    "\n",
    "ëª¨ë¸ì˜ ì„±ëŠ¥ì€ macro F1 Score í‰ê°€ì§€í‘œì— ë”°ë¼ ì±„ì ë©ë‹ˆë‹¤.\n",
    "ì œì¶œ CSV íŒŒì¼ì€ result.csv í˜•íƒœë¡œ ì œì¶œí•˜ì‹œì˜¤."
   ]
  },
  {
   "cell_type": "markdown",
   "id": "f08ec03f-59cc-49ad-a288-346f4e3dd1ac",
   "metadata": {
    "id": "bPT5gwB5VdlC"
   },
   "source": [
    "~~~\n",
    "pred\n",
    "0\n",
    "1\n",
    "0\n",
    "2\n",
    "0\n",
    "...\n",
    "~~~"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "7c8ecccd-ee19-47d7-91e8-017d834a44e6",
   "metadata": {},
   "source": [
    "## ğŸ“Œ My Code\n",
    "- **lightgbmì€ sklearn ì•ˆì— ì—†ê³ , ë°”ë¡œ import í•´ì¤˜ì•¼ í•¨. => íŒ¨í‚¤ì§€ ì„¤ì¹˜ë˜ì–´ ìˆì§€ ì•Šì•„ì„œ ì‹¤ì „ì—ì„œ í™œìš© ë¶ˆê°€ëŠ¥í•  ë“¯**\n",
    "- **RandomForestClassifier**: 0.8643039773063413\n",
    "- **HistGradientBoostingClassifier**: 0.9336837464154217"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 42,
   "id": "527d9265-d22e-441c-bba5-5443a0691dbb",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Index(['ì—°ë„', 'ì§€ì—­', 'ì‘ë¬¼ì¢…ë¥˜', 'í† ì–‘ìœ í˜•', 'ë“±ê¸‰'], dtype='object')\n",
      "RandomForestClassifier 0.8643039773063413\n",
      "HistGradientBoostingClassifier 0.9336837464154217\n"
     ]
    }
   ],
   "source": [
    "import pandas as pd\n",
    "train = pd.read_csv(\"https://raw.githubusercontent.com/lovedlim/inf/refs/heads/main/p4/9_2/farm_train.csv\")\n",
    "test = pd.read_csv(\"https://raw.githubusercontent.com/lovedlim/inf/refs/heads/main/p4/9_2/farm_test.csv\")\n",
    "\n",
    "# 1. ë°ì´í„° ìœ í˜• í™•ì¸\n",
    "# ê²°ì¸¡ì¹˜: ì—†ìŒ\n",
    "# ë²”ì£¼í˜•: ['ì§€ì—­', 'ì‘ë¬¼ì¢…ë¥˜', 'í† ì–‘ìœ í˜•', 'ë“±ê¸‰'] => 'ì—°ë„'ë¥¼ ë²”ì£¼ë¡œ ë³€í™˜í•´ì£¼ë©´ ë” ì„±ëŠ¥ì´ ì¢‹ì„ê¹Œ? 0.86792 (ê¸°ì¡´: 0.81631)\n",
    "# target: ë†ì•½ê²€ì¶œì—¬ë¶€\n",
    "# print(train.info())\n",
    "# print(test.info())\n",
    "# print(train.shape, test.shape) # (4000, 9) (1000, 8)\n",
    "# print(train.select_dtypes('object').columns)\n",
    "\n",
    "# 2. ë°ì´í„° ì „ì²˜ë¦¬\n",
    "# (1) X_full\n",
    "X = train.drop(['ë†ì•½ê²€ì¶œì—¬ë¶€'], axis=1)\n",
    "y = train['ë†ì•½ê²€ì¶œì—¬ë¶€']\n",
    "X_full = pd.concat([X, test], axis=0)\n",
    "\n",
    "# 'ì—°ë„'ë¥¼ ë²”ì£¼í˜•ìœ¼ë¡œ ë°”ê¿”ë³´ê¸°!\n",
    "X_full['ì—°ë„'] = X_full['ì—°ë„'].astype('str')\n",
    "print(X_full.select_dtypes('object').columns)\n",
    "\n",
    "# print(X_full.shape, X.shape, test.shape) # (5000, 8) (4000, 8) (1000, 8)\n",
    "\n",
    "# (2) ê²°ì¸¡ì¹˜ ì²˜ë¦¬ => Pass\n",
    "\n",
    "# (3) ìˆ˜ì¹˜í˜• ìŠ¤ì¼€ì¼ë§ => Pass\n",
    "\n",
    "# (4) ë²”ì£¼í˜• ì¸ì½”ë”©\n",
    "X_full = pd.get_dummies(X_full)\n",
    "# print(X_full)\n",
    "# print(X_full.shape) # (5000, 28)\n",
    "\n",
    "# 3. ë°ì´í„° ë¶„ë¦¬\n",
    "X = X_full[:train.shape[0]]\n",
    "X_test = X_full[train.shape[0]:]\n",
    "# print(X.shape, X_test.shape) # (4000, 28) (1000, 28)\n",
    "\n",
    "from sklearn.model_selection import train_test_split\n",
    "X_train, X_val, y_train, y_val = train_test_split(X, y, test_size=0.2)\n",
    "# print(X_train.shape, X_val.shape, y_train.shape, y_val.shape) # (3200, 28) (800, 28) (3200,) (800,)\n",
    "\n",
    "# 4. ëª¨ë¸ í•™ìŠµ ë° ê²€ì¦\n",
    "from sklearn.ensemble import RandomForestClassifier\n",
    "model = RandomForestClassifier()\n",
    "model.fit(X_train, y_train)\n",
    "y_val_pred = model.predict(X_val)\n",
    "# print(y_val_pred)\n",
    "# print(y_val_pred.shape) # (800,)\n",
    "\n",
    "from sklearn.ensemble import HistGradientBoostingClassifier\n",
    "model2 = HistGradientBoostingClassifier()\n",
    "model2.fit(X_train, y_train)\n",
    "y_val_pred2 = model2.predict(X_val)\n",
    "# print(y_val_pred2)\n",
    "# print(y_val_pred2.shape) # (800,)\n",
    "\n",
    "# 5. ëª¨ë¸ í‰ê°€\n",
    "from sklearn.metrics import f1_score\n",
    "f1_score_1 = f1_score(y_val, y_val_pred, average='macro')\n",
    "print('RandomForestClassifier', f1_score_1)\n",
    "\n",
    "f1_score_2 = f1_score(y_val, y_val_pred2, average='macro')\n",
    "print('HistGradientBoostingClassifier', f1_score_2)\n",
    "\n",
    "# 6. ê²°ê³¼ ì €ì¥\n",
    "y_pred = model.predict(X_test)\n",
    "# print(y_pred)\n",
    "# print(y_pred.shape) # (1000,)\n",
    "\n",
    "result = pd.DataFrame({'pred':y_pred})\n",
    "result.to_csv('result_92.csv', index=False)\n",
    "\n",
    "check = pd.read_csv('result_92.csv')\n",
    "# print(check)"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.12.6"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
